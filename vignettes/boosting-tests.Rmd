---
title: "Boosting tests"
author: Cameron Roach
output: 
  html_notebook: 
    number_sections: yes
    toc: yes
    toc_float:
      collapsed: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)

rm(list=ls())

require(dplyr)
require(tidyr)
require(readxl)
require(lubridate)
require(ggplot2)
require(plotly)
require(DT)
require(caret)
require(myhelpr)
require(doMC)

registerDoMC(cores = 3)

source("../R/loadData.R")
source("../R/clean-smd-data.R")

load_zones_ma <- c("SEMASS", "WCMASS", "NEMASSBOST")
load_zones <- c("ME", "NH", "VT", "CT", "RI", load_zones_ma)

smd <- load_smd_data(load_zones, root_dir = "./..")
smd <- clean_smd_data(smd, root_dir = "./..")
```

# TODO

* ~~Should try rerunning this once all the data issues have been sorted out (weird spike and drop possibly due to daylight savings)~~ DONE
* Think about if K-fold CV is correct. I think it is since we're doing an ex-ante forecast here.

# Introduction

Here I wish to test,

* Which of xgbTree and xgbLinear perform best when forecasting
* What impact does lagged variables have on model performance when boosting?

Electricity demand in the ME load zone will be used. Only working days will be considered (weekends and holidays are filtered). Dry bulb temperature and lags will be used as a predictors. Models will be assessed against each other using RMSE.

In addition to the xgboost models a simple linear regression model will be fitted to serve as a baseline.

## Lagged variable creation

```{r gen_dummy_vars}
iZ <- "ME"

smd <- smd %>%
  filter(Zone == iZ,
         Weekend == FALSE,
         Holiday_flag == FALSE) %>% 
  mutate(DryBulb_lag1 = lag(DryBulb, 1),
         DryBulb_lag2 = lag(DryBulb, 2),
         DryBulb_lag3 = lag(DryBulb, 3),
         DryBulb_lag4 = lag(DryBulb, 4),
         DryBulb_lag5 = lag(DryBulb, 5),
         DryBulb_lag6 = lag(DryBulb, 6),
         DryBulb_lag7 = lag(DryBulb, 7),
         DryBulb_lag8 = lag(DryBulb, 8),
         DryBulb_lag9 = lag(DryBulb, 9),
         DryBulb_lag10 = lag(DryBulb, 10),
         DryBulb_lag11 = lag(DryBulb, 11),
         DryBulb_lag12 = lag(DryBulb, 12),
         DryBulb_lag13 = lag(DryBulb, 13),
         DryBulb_lag14 = lag(DryBulb, 14),
         DryBulb_lag15 = lag(DryBulb, 15),
         DryBulb_lag16 = lag(DryBulb, 16),
         DryBulb_lag17 = lag(DryBulb, 17),
         DryBulb_lag18 = lag(DryBulb, 18),
         DryBulb_lag19 = lag(DryBulb, 19),
         DryBulb_lag20 = lag(DryBulb, 20),
         DryBulb_lag21 = lag(DryBulb, 21),
         DryBulb_lag22 = lag(DryBulb, 22),
         DryBulb_lag23 = lag(DryBulb, 23),
         DryBulb_lag24 = lag(DryBulb, 24),
         DryBulb_lag25 = lag(DryBulb, 25),
         DryBulb_lag26 = lag(DryBulb, 26),
         DryBulb_lag27 = lag(DryBulb, 27),
         DryBulb_lag28 = lag(DryBulb, 28),
         DryBulb_lag29 = lag(DryBulb, 29),
         DryBulb_lag30 = lag(DryBulb, 30),
         DryBulb_lag31 = lag(DryBulb, 31),
         DryBulb_lag32 = lag(DryBulb, 32),
         DryBulb_lag33 = lag(DryBulb, 33),
         DryBulb_lag34 = lag(DryBulb, 34),
         DryBulb_lag35 = lag(DryBulb, 35),
         DryBulb_lag36 = lag(DryBulb, 36),
         DryBulb_lag37 = lag(DryBulb, 37),
         DryBulb_lag38 = lag(DryBulb, 38),
         DryBulb_lag39 = lag(DryBulb, 39),
         DryBulb_lag40 = lag(DryBulb, 40),
         DryBulb_lag41 = lag(DryBulb, 41),
         DryBulb_lag42 = lag(DryBulb, 42),
         DryBulb_lag43 = lag(DryBulb, 43),
         DryBulb_lag44 = lag(DryBulb, 44),
         DryBulb_lag45 = lag(DryBulb, 45),
         DryBulb_lag46 = lag(DryBulb, 46),
         DryBulb_lag47 = lag(DryBulb, 47),
         DryBulb_lag48 = lag(DryBulb, 48),
         DryBulb_lag49 = lag(DryBulb, 49),
         DryBulb_lag50 = lag(DryBulb, 50),
         DryBulb_lag51 = lag(DryBulb, 51),
         DryBulb_lag52 = lag(DryBulb, 52),
         DryBulb_lag53 = lag(DryBulb, 53),
         DryBulb_lag54 = lag(DryBulb, 54),
         DryBulb_lag55 = lag(DryBulb, 55),
         DryBulb_lag56 = lag(DryBulb, 56),
         DryBulb_lag57 = lag(DryBulb, 57),
         DryBulb_lag58 = lag(DryBulb, 58),
         DryBulb_lag59 = lag(DryBulb, 59),
         DryBulb_lag60 = lag(DryBulb, 60),
         DryBulb_lag61 = lag(DryBulb, 61),
         DryBulb_lag62 = lag(DryBulb, 62),
         DryBulb_lag63 = lag(DryBulb, 63),
         DryBulb_lag64 = lag(DryBulb, 64),
         DryBulb_lag65 = lag(DryBulb, 65),
         DryBulb_lag66 = lag(DryBulb, 66),
         DryBulb_lag67 = lag(DryBulb, 67),
         DryBulb_lag68 = lag(DryBulb, 68),
         DryBulb_lag69 = lag(DryBulb, 69),
         DryBulb_lag70 = lag(DryBulb, 70),
         DryBulb_lag71 = lag(DryBulb, 71),
         DryBulb_lag72 = lag(DryBulb, 72),
         DewPnt_lag1 = lag(DewPnt, 1),
         DewPnt_lag2 = lag(DewPnt, 2),
         DewPnt_lag3 = lag(DewPnt, 3),
         DewPnt_lag4 = lag(DewPnt, 4),
         DewPnt_lag5 = lag(DewPnt, 5),
         DewPnt_lag6 = lag(DewPnt, 6),
         DewPnt_lag7 = lag(DewPnt, 7),
         DewPnt_lag8 = lag(DewPnt, 8),
         DewPnt_lag9 = lag(DewPnt, 9),
         DewPnt_lag10 = lag(DewPnt, 10),
         DewPnt_lag11 = lag(DewPnt, 11),
         DewPnt_lag12 = lag(DewPnt, 12),
         DewPnt_lag13 = lag(DewPnt, 13),
         DewPnt_lag14 = lag(DewPnt, 14),
         DewPnt_lag15 = lag(DewPnt, 15),
         DewPnt_lag16 = lag(DewPnt, 16),
         DewPnt_lag17 = lag(DewPnt, 17),
         DewPnt_lag18 = lag(DewPnt, 18),
         DewPnt_lag19 = lag(DewPnt, 19),
         DewPnt_lag20 = lag(DewPnt, 20),
         DewPnt_lag21 = lag(DewPnt, 21),
         DewPnt_lag22 = lag(DewPnt, 22),
         DewPnt_lag23 = lag(DewPnt, 23),
         DewPnt_lag24 = lag(DewPnt, 24),
         DewPnt_lag25 = lag(DewPnt, 25),
         DewPnt_lag26 = lag(DewPnt, 26),
         DewPnt_lag27 = lag(DewPnt, 27),
         DewPnt_lag28 = lag(DewPnt, 28),
         DewPnt_lag29 = lag(DewPnt, 29),
         DewPnt_lag30 = lag(DewPnt, 30),
         DewPnt_lag31 = lag(DewPnt, 31),
         DewPnt_lag32 = lag(DewPnt, 32),
         DewPnt_lag33 = lag(DewPnt, 33),
         DewPnt_lag34 = lag(DewPnt, 34),
         DewPnt_lag35 = lag(DewPnt, 35),
         DewPnt_lag36 = lag(DewPnt, 36),
         DewPnt_lag37 = lag(DewPnt, 37),
         DewPnt_lag38 = lag(DewPnt, 38),
         DewPnt_lag39 = lag(DewPnt, 39),
         DewPnt_lag40 = lag(DewPnt, 40),
         DewPnt_lag41 = lag(DewPnt, 41),
         DewPnt_lag42 = lag(DewPnt, 42),
         DewPnt_lag43 = lag(DewPnt, 43),
         DewPnt_lag44 = lag(DewPnt, 44),
         DewPnt_lag45 = lag(DewPnt, 45),
         DewPnt_lag46 = lag(DewPnt, 46),
         DewPnt_lag47 = lag(DewPnt, 47),
         DewPnt_lag48 = lag(DewPnt, 48),
         DewPnt_lag49 = lag(DewPnt, 49),
         DewPnt_lag50 = lag(DewPnt, 50),
         DewPnt_lag51 = lag(DewPnt, 51),
         DewPnt_lag52 = lag(DewPnt, 52),
         DewPnt_lag53 = lag(DewPnt, 53),
         DewPnt_lag54 = lag(DewPnt, 54),
         DewPnt_lag55 = lag(DewPnt, 55),
         DewPnt_lag56 = lag(DewPnt, 56),
         DewPnt_lag57 = lag(DewPnt, 57),
         DewPnt_lag58 = lag(DewPnt, 58),
         DewPnt_lag59 = lag(DewPnt, 59),
         DewPnt_lag60 = lag(DewPnt, 60),
         DewPnt_lag61 = lag(DewPnt, 61),
         DewPnt_lag62 = lag(DewPnt, 62),
         DewPnt_lag63 = lag(DewPnt, 63),
         DewPnt_lag64 = lag(DewPnt, 64),
         DewPnt_lag65 = lag(DewPnt, 65),
         DewPnt_lag66 = lag(DewPnt, 66),
         DewPnt_lag67 = lag(DewPnt, 67),
         DewPnt_lag68 = lag(DewPnt, 68),
         DewPnt_lag69 = lag(DewPnt, 69),
         DewPnt_lag70 = lag(DewPnt, 70),
         DewPnt_lag71 = lag(DewPnt, 71),
         DewPnt_lag72 = lag(DewPnt, 72))

train_data <- filter(smd, Year >= 2012, Year < 2015)

test_data <- filter(smd, Year == 2015)

head(train_data)
```


# xgbTree vs xgbLinear

Here we ignore any lagged variables and only test the predictive power of `xgbTree` against `xgbLinear` using DryBulb and Period as the only covariates.

```{r xgbTree_vs_xgbLinear}
xgb_fit <- list()

xgb_ctrl <- trainControl(method = "repeatedcv",
                         number = 5,
                         allowParallel = TRUE)

xgb_grid_tree <- expand.grid(nrounds = 500,
                        eta = c(0.01,0.1),
                        max_depth = 10,
                        gamma = 1,
                        colsample_bytree = 1,
                        min_child_weight = 1,
                        subsample = 1)

system.time({
  xgb_fit[["xgbTree"]] <- train(Demand ~ DryBulb + Period,
                                data = train_data,
                                method="xgbTree",
                                trControl = xgb_ctrl,
                                tuneGrid = xgb_grid_tree,
                                nthread = 1) # this arg stops OpenMP automatically running on linux, which stuffs up when also using doMC
})

xgb_grid_linear <- expand.grid(nrounds = 300,
                               lambda = 0,
                               alpha = 0,
                               eta = c(0.01, 0.1))

system.time({
  xgb_fit[["xgbLinear"]] <-  train(Demand ~ DryBulb + Period,
                                   data = train_data,
                                   method="xgbLinear",
                                   trControl = xgb_ctrl,
                                   tuneGrid = xgb_grid_linear,
                                   nthread = 1) # this arg stops OpenMP automatically running on linux, which stuffs up when also using doMC
})

xgb_fit
```

## Results

It looks like `xgbTree` and `xgbLinear` perform roughly the same, with RMSE values around 70 in their best performed cases. These RMSE values have been calculated using K-fold cross validation with 5 folds. The linear booster is roughly three times faster to fit than the tree boster.


# Lagged variable performance

We will proceed with the linear booster as it appears to be quicker to fit.

```{r train_lag_models}
system.time({
  xgb_fit[["xgbLinear_l1"]] <-  train(Demand ~ DryBulb + DryBulb_lag1 + Period,
                                   data = train_data,
                                   method="xgbLinear",
                                   trControl = xgb_ctrl,
                                   tuneGrid = xgb_grid_linear,
                                   nthread = 1) # this arg stops OpenMP automatically running on linux, which stuffs up when also using doMC
})

system.time({
  xgb_fit[["xgbLinear_l2"]] <-  train(Demand ~ DryBulb + DryBulb_lag1 + DryBulb_lag2 + Period,
                                   data = train_data,
                                   method="xgbLinear",
                                   trControl = xgb_ctrl,
                                   tuneGrid = xgb_grid_linear,
                                   nthread = 1) # this arg stops OpenMP automatically running on linux, which stuffs up when also using doMC
})

system.time({
  xgb_fit[["xgbLinear_lag3"]] <-  train(Demand ~ DryBulb + DryBulb_lag1 + DryBulb_lag2 + DryBulb_lag3 + DryBulb_lag4 + DryBulb_lag5 + DryBulb_lag6 + Period,
                                   data = train_data,
                                   method="xgbLinear",
                                   trControl = xgb_ctrl,
                                   tuneGrid = xgb_grid_linear,
                                   nthread = 1) # this arg stops OpenMP automatically running on linux, which stuffs up when also using doMC
})

system.time({
  xgb_fit[["xgbLinear_lag4"]] <-  train(Demand ~ DryBulb + DryBulb_lag1 + DryBulb_lag2 + DryBulb_lag3 + DryBulb_lag4 + DryBulb_lag5 + DryBulb_lag6 + DryBulb_lag24 + Period,
                                   data = train_data,
                                   method="xgbLinear",
                                   trControl = xgb_ctrl,
                                   tuneGrid = xgb_grid_linear,
                                   nthread = 1) # this arg stops OpenMP automatically running on linux, which stuffs up when also using doMC
})

system.time({
  xgb_fit[["xgbLinear_lag5"]] <-  train(Demand ~ DryBulb + DryBulb_lag1 + DryBulb_lag2 + DryBulb_lag3 + DryBulb_lag4 + DryBulb_lag5 + DryBulb_lag6 + DryBulb_lag24 + DryBulb_lag48 + DryBulb_lag72 + Period,
                                   data = train_data,
                                   method="xgbLinear",
                                   trControl = xgb_ctrl,
                                   tuneGrid = xgb_grid_linear,
                                   nthread = 1) # this arg stops OpenMP automatically running on linux, which stuffs up when also using doMC
})

system.time({
  xgb_fit[["xgbLinear_lag6"]] <-  train(Demand ~ DryBulb + DryBulb_lag24 + DryBulb_lag48 + DryBulb_lag72 + Period,
                                   data = train_data,
                                   method="xgbLinear",
                                   trControl = xgb_ctrl,
                                   tuneGrid = xgb_grid_linear,
                                   nthread = 1) # this arg stops OpenMP automatically running on linux, which stuffs up when also using doMC
})

system.time({
  xgb_fit[["xgbLinear_lag7"]] <-  train(Demand ~ DryBulb + DryBulb_lag3 + DryBulb_lag6 + DryBulb_lag24 + DryBulb_lag48 + Period,
                                   data = train_data,
                                   method="xgbLinear",
                                   trControl = xgb_ctrl,
                                   tuneGrid = xgb_grid_linear,
                                   nthread = 1) # this arg stops OpenMP automatically running on linux, which stuffs up when also using doMC
})

system.time({
  xgb_fit[["xgbLinear_lag8"]] <-  train(Demand ~ DryBulb + DryBulb_lag1 + DryBulb_lag2 + DryBulb_lag3 + DryBulb_lag4 + DryBulb_lag5 + DryBulb_lag6 + DryBulb_lag24 + DryBulb_lag48 + Period,
                                   data = train_data,
                                   method="xgbLinear",
                                   trControl = xgb_ctrl,
                                   tuneGrid = xgb_grid_linear,
                                   nthread = 1) # this arg stops OpenMP automatically running on linux, which stuffs up when also using doMC
})
```

## Results

Interestingly the more predictors we add the longer it takes to fit a model. This probably shouldn't come as a surprise given it means there is more data that the algorithm needs to deal with.

The RMSE scores for each of the models is plotted below.

```{r lagged_model_performance}
performance_df <- NULL
for (iM in names(xgb_fit)) {
  performance_df <- data.frame(
    Model = iM,
    RMSE = min(xgb_fit[[iM]]$results$RMSE)
  ) %>% 
    bind_rows(performance_df)
}

performance_df$Model <- factor(performance_df$Model,
                               levels = names(xgb_fit),
                               ordered = TRUE)

ggplot(performance_df, aes(x=Model, y=RMSE)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ggtitle("RMSE for boosted models")
```

So we see that the model that uses all lags performs best. It looks as though `xgboost` is good at handling extra variables.

# Testing a lot of variables

What happens if we create heaps of lagged predictors for both dry bulb AND dew point temperatures? Let's check! We will use all predictors in model 9 and 10, but model 10 also has L1 regularization and scaled predictors.

```{r crazy_predictor_test}
system.time({
  xgb_fit[["xgbLinear_lag9"]] <-  train_data %>% 
    select(Demand, Period, starts_with("DryBulb"), starts_with("DewPnt")) %>% 
    train(Demand ~ . ,
          data = .,
          method="xgbLinear",
          trControl = xgb_ctrl,
          tuneGrid = xgb_grid_linear,
          nthread = 1) # this arg stops OpenMP automatically running on linux, which stuffs up when also using doMC
})

xgb_grid_linear <- expand.grid(nrounds = 300,
                               lambda = 0,
                               alpha = 100, #c(1, 5, 10, 20, 50, 100),
                               eta = c(0.01, 0.1))

system.time({
  xgb_fit[["xgbLinear_lag10"]] <-  train_data %>% 
    select(Demand, Period, starts_with("DryBulb"), starts_with("DewPnt")) %>% 
    mutate_at(vars(starts_with("DryBulb"), starts_with("DewPnt")),
              scale, center = FALSE) %>% 
    train(Demand ~ . ,
          data = .,
          method="xgbLinear",
          trControl = xgb_ctrl,
          tuneGrid = xgb_grid_linear,
          nthread = 1) # this arg stops OpenMP automatically running on linux, which stuffs up when also using doMC
})
```

## Results

Plotting our new high-dimensional model RMSEs against the previous models shows that they ------------------. However, this performance is based on the training and validation data set. We still need to assess how each model performs on the test data set.

```{r crazy_model_performance}
performance_df <- NULL
for (iM in names(xgb_fit)) {
  performance_df <- data.frame(
    Model = iM,
    RMSE = min(xgb_fit[[iM]]$results$RMSE)
  ) %>% 
    bind_rows(performance_df)
}

performance_df$Model <- factor(performance_df$Model,
                               levels = names(xgb_fit),
                               ordered = TRUE)

ggplot(performance_df, aes(x=Model, y=RMSE)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ggtitle("RMSE for boosted models")
```

# Performance of models on test data

Let's calculate the RMSE scores for all of these models on the test data set. This will give a better idea of how well these models are really performing.

As expected, the overspecified model xgbLinear_lag9 performs relatively worse when using the test set. Weirdly, all the other models show improved performance when compared to the CV results, which is unexpected. This could be due to 2015 being an easier year to predict, but it is worth investigating. Model xgbLinear_lag5 is the best performed model.

```{r test_data_rmse}
performance_df <- NULL
for (iM in names(xgb_fit)[1:11]) {
  rmse <- mean((predict(xgb_fit[[iM]], test_data) - test_data$Demand)^2)^0.5
  
  performance_df <- data.frame(
    Model = iM,
    RMSE = rmse
  ) %>% 
    bind_rows(performance_df)
}

# models using scaled data
for (iM in names(xgb_fit)[-(1:11)]) {
  scaled_test_data <- test_data %>% 
    select(Demand, Period, starts_with("DryBulb"), starts_with("DewPnt")) %>% 
    mutate_at(vars(starts_with("DryBulb"), starts_with("DewPnt")),
              scale, center = FALSE)
  
  rmse <- mean((predict(xgb_fit[[iM]], scaled_test_data) - scaled_test_data$Demand)^2)^0.5
  
  performance_df <- data.frame(
    Model = iM,
    RMSE = rmse
  ) %>% 
    bind_rows(performance_df)
}


performance_df$Model <- factor(performance_df$Model,
                               levels = names(xgb_fit),
                               ordered = TRUE)

ggplot(performance_df, aes(x=Model, y=RMSE)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ggtitle("RMSE for boosted models")
```

